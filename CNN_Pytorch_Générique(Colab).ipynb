{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Pytorch_Générique(Colab).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "import os\n",
        "import pandas as pd\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import PIL.Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9KK897sJAGrF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement réalisé soit sur la GPU ou la CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "xMnf2z5xAN4U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Choix du fichier des labels & choix du dossier des images \"\"\"\n",
        "\n",
        "# Importer vos fichier de votre Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Saisir le nom du fichier csv et le chemin exact du dossier contenant les images\n",
        "\n",
        "file_path = input(\"Saisir le chemin du fichier des labels comme suit: gdrive/MyDrive/votre_fichier_csv_des_labels: \")\n",
        "folder_path = input(\"Saisir le chemin du fichier des labels comme suit: gdrive/MyDrive/votre_dossier_d'images: \")"
      ],
      "metadata": {
        "id": "xQn4IoLUAaxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Choix des hyperparamètres \"\"\"\n",
        "\n",
        "SPLIT = float(input(\n",
        "    \"Saisir le pourcentage de données dans l'ensemble d'entraînement (ex: saisir 0.7 pour 70% des données dans l'ensemble d'entraînement): \"))\n",
        "BATCH_SIZE = int(input(\"Saisir la taille du batch: \"))\n",
        "LABELS_COLUMN = int(input(\"Saisir l'index de la colonne des labels: \"))\n",
        "ID_COLUMN = int(input(\"Saisir l'index de la colonne des identifiants (noms des images): \"))\n",
        "IMAGE_SIZE = int(input(\"Saisir la taille de l'image: \"))\n",
        "IMAGE_CHANNELS = int(input(\"Saisir le nombre de canaux de votre image (3 pour RGB (couleurs) ou 1 (grayscale)): \"))\n",
        "IMAGE_SIZE2 = int(input(\"Saisir la taille de l'image en sortie de la seconde couche de convolution: \"))\n",
        "IMAGE_SIZE3 = int(input(\"Saisir la taille de l'image en sortie de la troisième couche de convolution: \"))\n",
        "IMAGE_SIZE4 = int(input(\"Saisir la taille de l'image en sortie de la quatrième couche de convolution: \"))\n",
        "KERNEL_SIZE = int(input(\"Saisir la taille du kernel (filtre): \"))\n",
        "STRIDE_SIZE = int(input(\"Définir le pas du kernel lorsqu'il se déplace sur l'image (ex: un pas de 1 signifie que le kernel se déplace pixel par pixel): \"))\n",
        "INPUT_SIZE = int(input(\"Saisir le nombre de neurones en entrée de la couche fully connected (si vous ne connaissez pas la formule, mettez une valeur aléatoire une erreur s'affichera 'mat1 and mat2 shapes cannot be multiplied' pour voir la réélle valeur de l'input_size qui correspond la colonne (format: nrow x ncol) de la mat1): \"))\n",
        "OUTPUT_SIZE = int(input(\"Saisir le nombre de neurones en sortie de la couche fully connected: \"))\n",
        "NUM_CLASSES = int(input(\"Saisir le nombre de classes/labels: \"))\n",
        "LEARNING_RATE = float(input(\"Saisir la vitesse d'apprentissage (learning rate): \"))\n",
        "EPOCHS = int(input(\"Saisir le nombre d'epochs: \"))"
      ],
      "metadata": {
        "id": "l4ewSO7aAuND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Écriture de notre propre jeu de données \"\"\"\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, label_file, root_dir, transform):\n",
        "        self.df = pd.read_csv(label_file)  # Ouverture du fichier contenant les labels normalisés\n",
        "        self.folder_dir = root_dir  # Chemin vers le dossier contenant les images à classer\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.df.iloc[idx, ID_COLUMN]  # colonne des identifiants des images\n",
        "        img_name = os.path.join(self.folder_dir,\n",
        "                                img_id)  # Récupération des images\n",
        "        imgs_set = PIL.Image.open(img_name).convert('RGB')  # Ouverture des images\n",
        "        label = torch.tensor(self.df.iloc[idx, LABELS_COLUMN],\n",
        "                             dtype=torch.float32)  # colonne contenant les labels\n",
        "\n",
        "        # Transformation des images\n",
        "        if self.transform is not None:\n",
        "            imgs_set = self.transform(imgs_set)\n",
        "\n",
        "        return imgs_set, label\n",
        "\n",
        "# Redimensionner l'image, convertir les PIL Images en tensor, convertir le type des images tensor en float32, normalisation des tensors\n",
        "all_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.PILToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float32),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "image_dataset = ImageDataset(label_file=file_path, root_dir=folder_path, transform=all_transforms)\n",
        "\n",
        "# Division du jeu de données en ensemble de test et d'entraînement\n",
        "train_size = int(SPLIT * len(image_dataset))\n",
        "test_size = len(image_dataset) - train_size\n",
        "X_train, X_test = random_split(image_dataset, [train_size, test_size])\n",
        "\n",
        "print(\"\\nNombre de données dans l'ensemble d'entraînement: \", len(X_train))\n",
        "print(\"Nombre de données dans l'ensemble de test: \", len(X_test))\n",
        "\n",
        "# Chargement de l'ensemble d'entraînement et l'ensemble de test\n",
        "train_dataloader = DataLoader(X_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(X_test, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "OJ21tx0BBMYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Création d'un CNN \"\"\"\n",
        "\n",
        "class ConvNeuralNet(nn.Module):\n",
        "    def __init__(self, imgs_channels, taille_image, size_kernel, taille_image2, stride_size, taille_image3, taille_image4, input_size, output_size, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=imgs_channels, out_channels=taille_image, kernel_size=size_kernel)\n",
        "        self.conv_layer2 = nn.Conv2d(in_channels=taille_image, out_channels=taille_image2, kernel_size=size_kernel)\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size=size_kernel, stride=stride_size)\n",
        "\n",
        "        self.conv_layer3 = nn.Conv2d(in_channels=taille_image2, out_channels=taille_image3, kernel_size=size_kernel)\n",
        "        self.conv_layer4 = nn.Conv2d(in_channels=taille_image3, out_channels=taille_image4, kernel_size=size_kernel)\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size=size_kernel, stride=stride_size)\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, output_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(output_size, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.max_pool1(out)\n",
        "\n",
        "        out = self.conv_layer3(out)\n",
        "        out = self.conv_layer4(out)\n",
        "        out = self.max_pool2(out)\n",
        "\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Création du modèle\n",
        "model = ConvNeuralNet(imgs_channels=IMAGE_CHANNELS, taille_image=IMAGE_SIZE, size_kernel=KERNEL_SIZE, taille_image2=IMAGE_SIZE2, stride_size=STRIDE_SIZE, taille_image3=IMAGE_SIZE3, taille_image4=IMAGE_SIZE4, input_size=INPUT_SIZE, output_size=OUTPUT_SIZE, num_classes=NUM_CLASSES)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "iNz5qe-eBTfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Configuration d'un CNN \"\"\"\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Classification multi-classes\n",
        "optimiseur = torch.optim.SGD(model.parameters(), LEARNING_RATE)"
      ],
      "metadata": {
        "id": "KhP6QFTDBYaz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Apprentissage d'un CNN \"\"\"\n",
        "\n",
        "print(\"\\n\\n###################################### ENTRAÎNEMENT ######################################\")\n",
        "model.train()  # Activer le mode entraînement\n",
        "loss_values = []\n",
        "for epoch in range(0, EPOCHS):\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "        # Enregistrer les tensors dans le device associé\n",
        "        images.to(device)\n",
        "        labels.to(device)\n",
        "\n",
        "        # Prédictions et calcul de l'erreur\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels.long())\n",
        "\n",
        "        # Mise à jour des paramètres de notre modèle\n",
        "        optimiseur.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiseur.step()\n",
        "\n",
        "    # Enregistrement de chaque erreur\n",
        "    loss_values.append((epoch + 1, round(loss.item(), 3)))\n",
        "\n",
        "    # Affichage\n",
        "    print('Epoch [{}/{}]\\n Loss: {:.3f}'.format(epoch + 1, EPOCHS, loss.item()))\n",
        "print(\"Entraînement terminé !!\")"
      ],
      "metadata": {
        "id": "QhxgtAyfBbBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation de la performance du modèle\n",
        "epochs, losses = zip(*loss_values)\n",
        "plt.plot(epochs, losses)\n",
        "plt.xlabel('EPOCHS')\n",
        "plt.ylabel('LOSS')\n",
        "plt.title('Erreur du modèle', fontsize=21)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AWDBskQRBed0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Évaluation d'un CNN \"\"\"\n",
        "\n",
        "print(\"\\n\\n###################################### EVALUATION ######################################\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_dataloader:\n",
        "        images.to(device)\n",
        "        labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Précision du modèle sur les {} images: {} %'.format(len(X_test), 100 * (round(correct / total, 3))))"
      ],
      "metadata": {
        "id": "6TF5swlNBg9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Sauvegarder le modèle \"\"\"\n",
        "\n",
        "print(\"\\n\\n###################################### SAUVEGARDE DU MODÈLE ######################################\")\n",
        "torch.save(model, \"gdrive/MyDrive/Classification_CNN.pth\")\n",
        "print(\"Modèle sauvegardé !\")"
      ],
      "metadata": {
        "id": "Nc270cLiBpI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}